{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn import metrics\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "import re\n",
    "import string\n",
    "import math\n",
    "\n",
    "total_documents = 4\n",
    "\n",
    "df = pd.read_csv('imdb_sup.csv', nrows=total_documents)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper functions for cleaning\n",
    "def remove_punc(word):\n",
    "    punc = '''-!()[]{};:\"\\,<>./?@#$%^&*_~'''\n",
    "    no_punc_word = word.translate(str.maketrans('', '', punc))\n",
    "    return no_punc_word\n",
    "\n",
    "def remove_BR(lst):\n",
    "    words = []\n",
    "    for word in lst:\n",
    "        if word.endswith('br'):\n",
    "            word = word[:-2]\n",
    "        words.append(word)\n",
    "    \n",
    "    return ' '.join(words)\n",
    "\n",
    "def make_lower(word):\n",
    "    return word.lower()\n",
    "\n",
    "def remove_numbers(lst):\n",
    "    no_num_list = [x for x in lst if not any(c.isdigit() for c in x)]\n",
    "    return ' '.join(no_num_list)\n",
    "\n",
    "def remove_words(lst):\n",
    "    extra_stops = ['aa', 'ab','br', 'us', 'mr', 'saw', 'until', 'no', 'when', 'with', \n",
    "            'like', 'just', 'even', 'it\\'s', 'i\\'m', \n",
    "            'who', 'i\\'ve', 'what', 'he', 'see', 'up','get', 'been',\n",
    "            'because', 'into', 'time', 'watch', 'â–','called', '2',\n",
    "             '10', 'said','their', 'then', 'can','two', 'go', 'also', 'seen', 'him',\n",
    "            'through', 'it', 'doesn\\'t', 'you\\'re', 'that\\'s', 'there\\'s',\n",
    "            'come', 'said', 'all.', 'screen', 'person', 'i\\'ll', 'is,'\n",
    "            '5', 'sandra', 'them.', '3', '.', 'he\\'s', 'man', 'they\\'re',\n",
    "            '\\\\\\x96', '--', 'i\\'d', 'is,', 'oh', 'one', 'much', 'movies',\n",
    "            'say', '4', '1', 'five', 'what\\'s', '15', 'ed', '...',\n",
    "            'movie', 'film','', '-', 'people', 'could', 'make', 'films', 'reviews']\n",
    "\n",
    "\n",
    "    stop_words = nltk.corpus.stopwords.words(\"english\")\n",
    "    stop_words = set(stop_words)\n",
    "    stop_words.update(extra_stops) \n",
    "\n",
    "    words = [word for word in lst if word not in stop_words]\n",
    "\n",
    "    return ' '.join(words)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_clean(message):\n",
    "  message = remove_punc(message)   # remove punctiation except - and \\'\n",
    "  message = remove_words(message.split())\n",
    "  message = remove_BR(message.split())\n",
    "  message = remove_numbers(message.split())\n",
    "  message = nltk.tag.pos_tag(message.split(), tagset='universal')\n",
    "  message = [word for word,tag in message if (tag == 'ADJ' or tag == 'ADV' or tag == 'VERB')]\n",
    "  message = ' '.join(message)\n",
    "  message = message.lower()\n",
    "\n",
    "  return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'loved think well played good critical clique almost would give going new repeating know exactly happen progressive tell meant would sad tell meant kidding'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_str = \"I loved a country of Wakanda, the culture, world, scenery and people. I think it was well played, CGIs were very good and story but, I have to be critical about some things. -2 stars because of clique and predictability. If I haven't seen almost all Marvel movies I would give it more stars but they are going on every new hero with one script and they are repeating it over and over again. I know exactly what and when it will happen. -1 star for progressive propaganda and hypocrisy. Example: if Ross tell something about skin color in the move but he didn't meant to insult somebody it would be sad. when Shuri tell Ross 'Colonizer' and she meant as insult, it is ok and no racist. when I saw that I was like are you kidding me?\"\n",
    "text_clean(test_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleans all reviews in dataset\n",
    "df['Review'] = df['Review'].apply(text_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffles data entries\n",
    "# dff = df.sample(frac=1).reset_index(drop=True)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>coupled makes finest ever aired holds emotional strong enough never preserved ultimate mindblowingly moving looked quite remains top</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>extremely low recorded however good easy follow shooting sexually abusive released psychiatric secretly affair renting first see's acts innocent killed attempted hot acting later kill supposedly loves find good know whole falling</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>best known tough played quite lot first last musical would star singing quite needs bad apparently dancing early started take big actually weird took musical obviously feels ease totally different accustomed seeing directed perhaps best successful earliest pretty defined musical responsible always light else really never really singing featured later made mainly usual light set musical predictable nevertheless fun simple simply makes entertaining portraying weird total gets abandoned consists musical musical ending amusing well done big musical young often played little early including musical earlier recommendable early</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>following brilliant excellent third sadly final incorruptible samuraiconstable brilliantly played great fighting well enormous sexual big made became instant eager sequels full finally stumbled recently third quite brilliant definitely great japanese foregoing brilliantly comical crudely humorous immediately starts fabulously female always wanted sleep lead promising beginning awesome know personal seems written specifically obstinate constable deliberately insults unique include raping female interrogated immediately fall due sexual enormous rather grotesque routine give cool good hilariously eccentric sadly last awesomely sleazy made would happily watched entire third compared definitely mustsee made</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Review  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     coupled makes finest ever aired holds emotional strong enough never preserved ultimate mindblowingly moving looked quite remains top   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    extremely low recorded however good easy follow shooting sexually abusive released psychiatric secretly affair renting first see's acts innocent killed attempted hot acting later kill supposedly loves find good know whole falling   \n",
       "2                                                                                     best known tough played quite lot first last musical would star singing quite needs bad apparently dancing early started take big actually weird took musical obviously feels ease totally different accustomed seeing directed perhaps best successful earliest pretty defined musical responsible always light else really never really singing featured later made mainly usual light set musical predictable nevertheless fun simple simply makes entertaining portraying weird total gets abandoned consists musical musical ending amusing well done big musical young often played little early including musical earlier recommendable early   \n",
       "3  following brilliant excellent third sadly final incorruptible samuraiconstable brilliantly played great fighting well enormous sexual big made became instant eager sequels full finally stumbled recently third quite brilliant definitely great japanese foregoing brilliantly comical crudely humorous immediately starts fabulously female always wanted sleep lead promising beginning awesome know personal seems written specifically obstinate constable deliberately insults unique include raping female interrogated immediately fall due sexual enormous rather grotesque routine give cool good hilariously eccentric sadly last awesomely sleazy made would happily watched entire third compared definitely mustsee made   \n",
       "\n",
       "   Rating  Sentiment  \n",
       "0      10          1  \n",
       "1       8          1  \n",
       "2       8          1  \n",
       "3       8          1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "df\n",
    "# dff\n",
    "# print(dff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stemming program\n",
    "porterstemmer = PorterStemmer()\n",
    "\n",
    "def steming(message):\n",
    "  list = (porterstemmer.stem(word) for word in message.split());\n",
    "  print(\"List is: \", list)\n",
    "  return[porterstemmer.stem(word) for word in message.split()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       coupled makes finest ever aired holds emotional strong enough never preserved ultimate mindblowingly moving looked quite remains top\n",
      "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      extremely low recorded however good easy follow shooting sexually abusive released psychiatric secretly affair renting first see's acts innocent killed attempted hot acting later kill supposedly loves find good know whole falling\n",
      "2                                                                                       best known tough played quite lot first last musical would star singing quite needs bad apparently dancing early started take big actually weird took musical obviously feels ease totally different accustomed seeing directed perhaps best successful earliest pretty defined musical responsible always light else really never really singing featured later made mainly usual light set musical predictable nevertheless fun simple simply makes entertaining portraying weird total gets abandoned consists musical musical ending amusing well done big musical young often played little early including musical earlier recommendable early\n",
      "3    following brilliant excellent third sadly final incorruptible samuraiconstable brilliantly played great fighting well enormous sexual big made became instant eager sequels full finally stumbled recently third quite brilliant definitely great japanese foregoing brilliantly comical crudely humorous immediately starts fabulously female always wanted sleep lead promising beginning awesome know personal seems written specifically obstinate constable deliberately insults unique include raping female interrogated immediately fall due sexual enormous rather grotesque routine give cool good hilariously eccentric sadly last awesomely sleazy made would happily watched entire third compared definitely mustsee made\n",
      "Name: Review, dtype: object\n"
     ]
    }
   ],
   "source": [
    "train_X = df['Review'].head(4)  \n",
    "# train_Y = dff['Rating'].head(4)  \n",
    "test_X = df['Review'].tail(4) \n",
    "# test_Y = dff['Rating'].tail(4)\n",
    "print(test_X)\n",
    "# print(train_X)\n",
    "# print(dff['Review'])\n",
    "# steming(dff['Review'].head(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sad', 2]\n",
      "['mad', 1]\n",
      "['plot', 1]\n",
      "['bad', 1]\n",
      "['guess', 1]\n"
     ]
    }
   ],
   "source": [
    "#tf idf\n",
    "# tf_idf = TfidfVectorizer(tokenizer=steming)\n",
    "#applying tf idf to training data\n",
    "# X_train_tf = tf_idf.fit_transform(train_X)\n",
    "#applying tf idf to training data\n",
    "# X_train_tf = tf_idf.transform(train_X)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# freq_of_t = 2\n",
    "# tot_docs = 4\n",
    "term = []\n",
    "for words in test_X:\n",
    "    term.append(words)\n",
    "s = ' '\n",
    "s = s.join(term)\n",
    "\n",
    "# Method for finding words and reqquency \n",
    "\n",
    "\n",
    "class calculateWordsWithFreq:\n",
    "\n",
    "    def __init__(self, words, freq):\n",
    "        self.words = words\n",
    "        self.freq = freq\n",
    "\n",
    "    def sortByFreq(list):\n",
    "        return list[1]\n",
    "\n",
    "    \n",
    "    def wordsWithFreq(str):\n",
    "    \n",
    "        # break the string into list of words\n",
    "        str = str.split()        \n",
    "        wordsList = []\n",
    "        freqList = []\n",
    "        wordsAndFreqList = []\n",
    "    \n",
    "        # loop till string values present in list str\n",
    "        for i in str:            \n",
    "            if i not in wordsList:\n",
    "                wordsList.append(i)     \n",
    "                \n",
    "        for i in range(0, len(wordsList)):\n",
    "    \n",
    "            # count the frequency of each word(present\n",
    "            # in str2) in str and print\n",
    "            freqList.append(str.count(wordsList[i]))\n",
    "        wordsFreqList = dict(zip(wordsList, freqList))\n",
    "\n",
    "        # print(sorted(wordsFreqList, key=wordsFreqList.get, reverse=True))\n",
    "        for w in sorted(wordsFreqList, key=wordsFreqList.get, reverse=True):\n",
    "            wordsAndFreqList.append( [w, wordsFreqList[w]])\n",
    "            # return wordsAndFreqList\n",
    "\n",
    "            # print (wordsAndFreqList)\n",
    "            # return (wordsAndFreqList)\n",
    "        return wordsAndFreqList\n",
    "\n",
    "         \n",
    "\n",
    "\n",
    "    def calc_tf_idf():\n",
    "        # Tf IDf calculation \n",
    "        # ********************* \n",
    "        # tot_docs_for_t = 6\n",
    "\n",
    "        n = total_documents\n",
    "        t = s\n",
    "\n",
    "        tf = freq_of_t\n",
    "        df_t = tot_docs_for_t\n",
    "\n",
    "        # for smooth \n",
    "        idf_of_t_s = math.log(((1 + n)/(1+ df_t)) + 1)\n",
    "\n",
    "        # for not_smooth \n",
    "        idf_of_t = math.log((n/df_t)+1);\n",
    "\n",
    "        tf_idf = round(tf * idf_of_t_s, 4);\n",
    "\n",
    "        # print (\"Term is: \", t)\n",
    "        print(\"tf is: \", tf)\n",
    "        print(\"idf of t is: \", tf)\n",
    "        print (\"tf_idf is: \", tf_idf)\n",
    "\n",
    "\n",
    "# ********************* \n",
    "# Tf IDf calculation \n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "# ***************\n",
    "demoText = \"It was a very very sad movie and I am very very mad about the plot but very sad is not bad I guess\"\n",
    "demoText = text_clean(demoText)\n",
    "\n",
    "resultList = calculateWordsWithFreq.wordsWithFreq(demoText)\n",
    "print(*resultList, sep=\"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
